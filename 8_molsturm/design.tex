\section{\molsturm program design}
\label{sec:MolsturmDesign}

As mentioned above the main target for the current design of \molsturm
is to yield a framework,
which supports notions towards novel quantum-chemical methods,
including methods where unusual discretisation approaches
or new types of basis functions are employed.
Ideally for this adding
new basis functions becomes kind of plug-and-play,
such that one only implements a minimal interface
towards an integral library and the rest of \molsturm,
\ie the \SCF and the Post-HF methods would just work
in a preliminary manner.
Many details regarding the numerical and algorithmic treatment
will most likely still need to be optimised thereafter,
such that high-level access to influence
all kinds of parameters of the \SCF scheme or the
diagonalisation algorithms are absolutely key.
Additionally such a new method would need to be tested and evaluated
towards their overall usefulness towards standard problem
of quantum-chemical modelling.
These tasks are usually both highly repetitive and again
require access into many layers of a quantum-chemistry program
to obtain the quantities to compare.
Aspects such as these motivate
the following overall design goals for the \molsturm project.

\paragraph{Enable rapid development:}
In the early stages of developing new quantum-chemical algorithms
it is often not clear how well these algorithms perform
or if they even meet the expected requirements.
Before worrying about making the algorithm fast,
one therefore first wants to know whether it even works.
A light-weight framework, which possesses the flexibility
to quickly combine or amend what is already implemented is very important for this.
The syntax of the resulting code should be high-level and intuitive,
resembling the physical formulae as much as possible.
To make the initial implementation easy for people
not entirely familiar with all tricks of the trade,
the details regarding the numerics and the linear algebra
should be mostly hidden in the code.
Especially in highly interdisciplinary subjects such as quantum chemistry
too often PhD students are rather unfamiliar to coding and numerics
and thus spend half a year to understand the clunky programs,
a year to implement the method,
just to find that it did not quite work that well.
Still influencing the algorithmic details
will in many cases be required at a later step.
Ideally this can be done by the means of changing mere parameters
directly from the user interface and
without changing the code very much,
such that it stays nice and clean for the next feature to be implemented.
A careful reader should have noticed that the \lazyten lazy matrix library,
described in the previous chapter,
covers many of the aspects mentioned here.
This is of course no surprise and explains why \lazyten has
become one of the key ingredients to \molsturm.
For some more details see \vref{sec:MolsturmPython}.
%
%
\begin{figure}
	\centering
	\includeimage{8_molsturm/molsturm_structure}
	\caption[Structure of the \molsturm package]
	{Structure of the \molsturm package. Shown are the five major
	modules of the package,
	along with the set of integrals accessible from \gint and the set of post-HF method,
	which can be used together with \molsturm.
	Only the modules inside the red box are part of \molsturm.
	The blue boxes are all external packages.
	The greyed-out boxes are planned, but not yet implemented.
	}
	\label{fig:structureMolsturm}
\end{figure}
\paragraph{Modular design with low code-complexity:}
The aspired flexibility of \molsturm as well as the intended
strong separation between high-level code describing algorithms
and low-level code dealing with the numerics,
necessarily calls for proper modularisation.
Even though our current design takes our experiences with many types
of basis functions into account,
it is very likely that we missed certain aspects,
which will make major restructuring unavoidable in the future.
To proactively account for this \molsturm consists of five small modules,
which are designed as layers, see figure \vref{fig:structureMolsturm}.
The top layer, ``\molsturm'', defines the application programming interface~(API),
by which other programs may control the flow of \molsturm or exchange data.
Unlike the other layers, which are mostly implemented in \cpp,
the \molsturm layer is mainly \python.
\gint, the \textit{general integral library},
provides a single link to multiplex between the supported integral calculation back ends.
\gscf implements a couple of \contraction-based \SCF schemes
following the general two-step Fock-update, coefficient/density-matrix-update structure,
we mentioned in section \ref{sec:SCFtakeaway}.
\gscf is written on top of \lazyten,
both to make use of its linear algebra abstraction
as well as the generality of the lazy matrix formalism
to work on dense, sparse and \contraction-based Fock matrices
under the same syntax.
Finally \krims is the library for common utility \textit{Krims}krams%
\footnote{German for ``odds and ends''}.
In our design we made sure
that dependencies are only downwards, never sideways or upwards,
to make it easy to replace libraries at a later point.
%
%
\paragraph{Plug-and-play implementation of new discretisations:}
When attempting to implement a new basis function type or an unusual discretisation technique
in existing quantum-chemistry packages,
there is one rather significant obstacle:
Implicit assumptions about the numerical properties of the employed basis
are scattered around the sometimes rather large codes.
Using the lazy matrix language of \lazyten,
we have achieved to centralise the basis function specifics as much as possible
at a single place,
namely the implementation of the \contraction expressions
of the integral lazy matrices.
This takes place in our integral interface \gint,
where all properties of the basis function type
as well as the precise back end implementation
regarding symmetries, selection rules, sparsity properties
or evaluation schemes are known and can be fully exploited.
In line with the final example presented in section \vref{sec:LazytenExamples},
the \SCF and post-\HF methods only need to care about the
integral lazy matrix objects,
being completely agnostic to the precise nature of the \contraction expression.
The result of these efforts is that switching from one implemented
basis function type to another can be achieved by merely passing
an appropriate string parameter.
All that effectively changes is the collection of lazy matrices,
which is exposed to the \SCF and all methods building on top
of the \SCF results.
Trying a new basis function type
or a new computational back end for the integral values
thus becomes really plug and play:
One implements the respective collection of lazy matrices and selects
it using the appropriate parameter.
For more details regarding this aspect see section \vref{sec:GscfGint}.
%
%
\paragraph{Easy interfacing with existing code:}
The evaluation and assessment of new quantum-chemical methods
necessarily implies that one needs to test their performance
towards standard problems of quantum chemistry.
This is especially true for new discretisation methods.
Implementing everything from scratch,
however, is a rather daunting task.
For this reason it is explicitly \emph{not} our goal
to create yet another fully-fledged quantum chemistry package
as well as the surrounding ecosystem around it.
Instead \molsturm is designed as a small package,
where both the full package as well as the individual modules
can be readily incorporated into other infrastructures
or used on their own for teaching and experimentation.
Overall our goal here is not to force a particular ``\molsturm-way'' upon
our users,
much rather provide well-documented and open interfaces,
with which it is easy to for them to interact with \molsturm
exactly how it fits there workflow best.
In this notion we want our \molsturm interface 
to be flexible enough such that interacting
with third-party packages can be easily achieved,
thus building on the hundreds of man-years,
which went into the development of already existing quantum-chemistry codes,
and extend \molsturm beyond the scope originally intended.
For details see section \vref{sec:MolsturmPython}
as well as the examples in section \vref{sec:MolsturmExamples}.

\todoil{Move the next paragraph somewhere else?}
\paragraph*{}
Within the setting of the above goals not only the \SCF of \molsturm
has become agnostic to the type of basis function used for the discretisation.
Once the \SCF orbitals have been obtained,
the remainder of a calculation, \eg a Post-\HF method in an external library,
can be formulated entirely in the \SCF orbital basis
and without any reference to the underlying basis functions.
Because of this \molsturm is essentially a mediator
to produce \SCF results employing arbitrary discretisations
on which one can stick any Post-\HF method we have interfaces for.
Experimenting between different discretisations
and comparing the results obtained can happen on a common ground,
yet still with access to a large range of quantum-chemical methods.
Even different integral back ends
could be compared against another using the identical \SCF of \molsturm.

In the following sections we will discuss some of the
aforementioned design aspects in more detail.

\subsection{The interplay of self-consistent field algorithm and integral library}
\label{sec:GscfGint}
About interplay between \gint and \gscf
separation of \SCF algorithm and discretisation numerics

Conceptionally an SCF algorithm is entirely independent of the type of basis function.
One could think of it very much as a numerical technique to solve
an non-linear eigenvalue problem by linearisation.

In chapter \vref{ch:NumSolveHF} we looked at various ways to solve the
\HF equations both with respect to different types of basis functions
for the discretisation as well as different \SCF algorithms.
Our conclusion was firstly that all \SCF schemes can be
condensed into the similar structure of a two-step process,
where a Fock-update step and a coefficient-update or a density-update step
repeat each other until convergence.
Secondly we mentioned that a \contraction-based ansatz could result in \SCF schemes,
which are agnostic to the type of basis function used.
The lazy matrix formalism and the corresponding \lazyten library,
introduced in the previous chapter,
provided ways to express \contraction-based algorithms at a high level.
Overall this means that the details of the \contraction implementation,
\ie the part deviating between different types of basis functions,
could be abstracted from the implementation of the \SCF algorithm
and vice versa.
We already briefly mentioned this in a concluding example
in section \vref{sec:LazytenExamples}.

%----
lazyten layer
An additional advantage of such a layer would be that
modifications of the system matrix can be transparently expressed
to the iterative schemes.
For example adding extra terms to the Fock matrix
describing an electric field or a polarisable embedding
or other contributions does not really require
any change to the \SCF code at all.
A good layer of abstraction between the actual \SCF algorithm
and the implementation of the matrix-vector contractions
is therefore highly desirable to enable flexibility on both sides.

need flexibility in matrix expressions in real-world application
like \SCF (extra terms of varying complexity from external field,
polarisable embedding, fragment approaches, and so on)
non-linearity of Coulomb and Exchange
would be nice to transparently express this
% ----

From the point of view of \gscf,
on the other hand,
the lazy matrices for all types of basis functions look alike.
In other words by the means of the lazy matrices
the algorithms in \gscf
can be written in such a high-level manor,
that they are entirely independent of the precise matrix structure.
Consequently they are independent of the choice of basis function type as well.



\todoil{Fock matrix $\Leftrightarrow$ Kohn-Sham matrix $\Leftrightarrow$ Problem matrix
to make clear that \gscf is not only for HF problems }


Similar to the \molsturm interface layer when it comes to Post-HF methods,
\gint does not implement any routine for computing the integrals.
Instead it just acts as a broker,
which presents a common interface for all available basis function types
and third-party integral backend libraries.

When a calculation starts,
\molsturm passes \gint the set of parameters,
which are relevant for the selection and setup of the integral backend,
like for example the Coulomb-Sturmian exponent or the Gaussian basis set information.
In return \gint provides \molsturm with a collection of lazy matrices,
where each lazy matrix represents a single integral for this
type of basis functions.
For example the nuclear attraction matrix, the kinetic operator matrix,
the coulomb matrix and the exchange matrix each exist as separate
lazy matrix objects.
These integral objects may then be combined
in an arbitrary manor to form the Fock matrix or Kohn-Sham matrix
expression by just forming linear combinations.
The resulting Fock matrix expression is then typically passed onto \gscf,
where the SCF problem is solved.

The generality of the lazy matrices allows the interface of \gint
to be entirely independent of the structure
which is used to represent the integral data internally.
This implies that all code inside \molsturm,
which works with the integral objects,
hence becomes independent of the way the integral data is represented
or how the evaluation of the \contraction function is actually performed.
\gint may freely choose the scheme for evaluating a matrix-vector
product or for example the sparsity structure which is used to
represent the data of the integral matrix
without this having any impact towards other parts of \molsturm.

Using lazy matrices furthermore has an advantage for
dealing with the non-linearity of the coulomb and exchange matrices:
The lazy matrix formalism of \lazyten provides the possibility
to implement a special \update function,
which can be used to update internal state of a lazy matrix.
The coulomb and exchange lazy matrices
may use this function to retrieve a new set of coefficients from an
SCF algorithm and update
their internal state accordingly.
As we will discuss in the next section \gscf makes frequent use of this feature.

Currently \gint only offers two types of basis functions,
namely Gaussian integrals and atomic Coulomb-Sturmians,
both available in at least two different implementations.
For example Gaussian integrals for \gint are available from either one of 
\libint by Valeev et al.\cite{Libint2,Libint2_231}
or \libcint by Sun et al.\todo{cite} 
under a common interface.
The design of \gint makes it furthermore very simple to extend the types of integrals
available in \molsturm:
The function calls which compute the integral values only need to be wrapped
inside lazy matrix objects and the resulting integral collection needs to be registered
with \gint.
For example the support for \libcint was added in just two days of work.

Note that this does not even require changing a single line of code inside \gint.
One could achieve this by linking the library into \molsturm at compile time.

\gscf assumes two-step \SCF process,
which is prefectly supported by the lazy matrices returned by \gint
by their \update function.

Currently all algorithms which are implemented in \gscf are coefficient-based SCF algorithms.
This is not strictly speaking required by the library,
but it has the advantage that for some basis function types
the computational scaling of the \contraction-function
of the Fock matrix expression can be reduced by an order of magnitude.
An example are the Coulomb-Sturmians.
\todoil{Maybe go into this a little in the previous sections and refer up}
Furthermore the density-matrix based algorithms
we have encountered so far could be reformulated as coefficient-based schemes
or were easily approximated to work as such.
For example we have implemented a variant of the original ODA,
which is suitable for a coefficient-based setting by truncating
the history of SCF steps considered in order to compute the optimal damping.
Talk about the implemented algorithms

be sure to emphasise that all lazyten code could be still used for dense computations

point out that parameters for \lazyten, eg with respect to the solvers
can actually be passed easily from the high-level \python interface of \molsturm

\subsection{\molsturm \python interface}
\label{sec:MolsturmPython}

%----
During development or debugging of a new method,
one often wants to interfere with the progress of a calculation
or be able to quickly access intermediate results graphically.
\molsturm aids such efforts by strongly integrating
with kk


Assessing a quantum-chemical method towards its usefulness
regarding standard problems typically implies repetitive
benchmark calculations of new and old approaches
as well as comparison of the results.
Often this task is highly repetitive and
a high degree of automatisation is required.
\molsturm aids such efforts by allowing for easy
data retrieval and post-processing 

Easy data retrieval and post processing (see examples)
Support iterative approach to problems by archival
and storage of computational parameters

Support iterative approach to quantum-chemical modelling:
Iterative process

Especially the ability to archive a large portion of the calculation
furthermore allows to exploit previous results when performing
further calculations as well as delaying the analysis
to a later point when \eg more knowledge about the
problem has been obtained to decide what exactly to look at.
%
feedback loop
Firstly it makes it easy to interactively work with \molsturm
from a shell. This reduces the feedback loop for small calculations
or during debugging.  If one uses \molsturm from a Jupyter notebook \cite{Jupyter},
one can even perform calculations and view plots interactively from within a web browser.
%----

Right now very simple and not efficient
Refer to examples as needed



Furthermore well-documented and open interfaces
as well as compliance with the available standards
allow easy integration of other frameworks to extend
the functionality of a package even beyond the scope
which was intended in the first place.
Only took order of days to interface with \pyscf and \adcman
high level interfaces.


Additionally this interface makes it
convenient to re-use existing software modules
together with \molsturm's \SCF.
In this manner we have already managed to link \molsturm to \pyscf~\cite{Sun2017}
for performing full configuration interaction~(FCI) calculations
and recently \adcman~\cite{Wormit2014}
for computing excited state energies at \ADC(2),
\ADC(2)-x and \ADC(3)~\cite{Schirmer1982,Trofimov1999} level.


For example the Full-CI interface to \pyscf was realised in only two days,
but still is general enough to work for Sturmians GTOs and theoretically
all basis function types which are implemented in our integral backend.
\todoil{Change to also mention CC if we get there}
In another proof-of-concept project of ours we just managed to
implement ADC(2)-x on top of \molsturm in less than 10 days in \python.


The topmost \molsturm layer handles calculation set-up 
(e.g., definition of molecules, basis set choice, choice 
of SCF-calculation scheme, et cetera), as well as interfacing 
to the outside world. \molsturm can be controlled in two ways: 
directly as a \cpp library, which is most convenient if it is to 
be called from within a quantum chemistry code written in \cee, \cpp, 
or \fortran; or it can be controlled through a \python interface.

We purposefully do not define a new ``input format'': calculations are 
controlled more cleanly and flexible by simply using
\python scripts (or calling it directly from a host quantum 
chemistry package) to drive calculation.
By calling simple interface functions, an SCF calculation can be set
up, and the appropriate integrals passed on to Post-HF calculations
if desired. The next section shows examples of how this is done.

Refer to the ideas of \pyscf
(input format)

Secondly this gives the user full flexibility
of how to embed \molsturm in his or her workflow.
From the \python interface, all data from \molsturm is available
in plain \numpy arrays, so the user can easily do
any kind of standard processing from \python
after or during a calculation.

python packages and for example jupyter


Furthermore \numpy arrays have become the \textit{de facto} standard
for storing and manipulating matrices or tensors in \python.
All third-party quantum chemistry codes which
offer a \python interface
either use \numpy arrays themselves or
provide utility functions to convert to and
from \numpy arrays.
\todoil{check if this is true and cite them}
The same is true for typical \python packages used for plotting or
data manipulation (matplotlib, scipy, pandas).

Thirdly by the means of interface generators
like SWIG \todo{cite} \numpy arrays can be converted to plain
\cee arrays for calling \cpp, \cee or \fortran code,
such that even low-level libraries can be employed
from \numpy arrays.



\subsection{Programming guidelines and paradigms}
\label{sec:ProgrammingGuidelines}



Testing
modularisation
combination of high-level and low-level code

A very important subsidiary to good software design is a flexible testing framework.
A test suite which is simple to execute, fast and easy to expand not only allows to verify
that the current status of a piece of software is correct,
but it also allows to verify that all future changes do not break anything.
This includes of cause the potential adaption of the design in the future,
which might involve changing any of the already existing interfaces.
A strong test suite aids with this procedure,
since one can perform these changes in a sequence of many small steps,
verifying the correctness of the software on the way.

For this reason \molsturm comes with an extensive test framework
with roughly four types of tests.
Firstly there are \term{unit tests},
which test the functionality of a single function or code unit in a couple of hard-coded examples.
Further we have \term{functionality tests},
which test a larger portion of code and are meant to ensure that
the results of \molsturm agree between different versions.
Thirdly the \term{reference tests} compare
the results of \molsturm to other quantum-chemistry packages.
Especially in \lazyten we furthermore make use of yet another type of tests,
namely so-called \term{property-based tests}.
This testing technique uses the expected properties of a code unit
to randomly generate test cases and to verify the result.
On failure the generated test cases are simplified until the most simple,
failing test case is found.
This is really helpful for debugging and in order to reduce the human aspect in testing.

Next to combining various different types of tests
other key principles in the design of our test suite were that our tests should be simple
to execute and take only a couple of minutes.
This not only makes it easier to motivate others to use the tests, too,
but it also allows to fully automate the whole testing process as well.
\todoil{I feel we should explicitly mention github and Travis-CI to show them some credit for this awesome work.}
In our case any commit to our repositories starts up a couple of virtual machines,
which build \molsturm and run the test suite for a couple of common compilers and
build configurations.
A commit into the stable source code branch is only accepted if the test suite passes.

In our test suite even the work of adding a new test is somewhat automated.
For example in order to add a new reference test for a new feature
or a case where a bug was discovered,
one simply adds a small configuration file to a special directory,
which defines the testing parameters.
A \python script, which is part of the test suite,
then automatically executes the third party program and extracts the reference results in a format,
which is understood by the \molsturm test suite.
When the test suite is executed all such reference results are read and
\molsturm is executed and tested for each of them.

\todoil{Mention test coverage ???}

\todoil{We probably should not keep this next paragraphs here}
On the side of the \molsturm code we employ \term{assertive programming} to assure that
\molsturm crashes with a very detailed backlog whenever an unexpected behaviour happened.
By the means of a dual build system setup, we achieve that a Debug version
(including heavy assertive checks) and a Release version
(without heavy assertive checks) are compiled side-by-side.
This allows to use the Debug version with a lot of assertions,
potentially even in the inner loops,
to be used for trial runs and the Release version with less assertions for productive runs.
Switching between Debug and Release from \molsturm's python interface is very simple and
only requires to recompile a few files,
since in normal build conditions Release and Debug have already been built.

By the means of checkpointing one could further use the Release version to get an erroneous
part of \molsturm and the Debug version to step-by-step test what goes wrong.
The detailed traceback on failure of an assertion can then be used to analyse the problem quickly.
