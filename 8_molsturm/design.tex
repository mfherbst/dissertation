\section{\molsturm program design}
\label{sec:MolsturmDesign}

As mentioned above the main target for the current design of \molsturm
is to yield a framework,
which supports notions towards novel quantum-chemical methods,
including methods where unusual discretisation approaches
or new types of basis functions are employed.
Ideally for this adding
new basis functions becomes kind of plug-and-play,
such that one only implements a minimal interface
towards an integral library and the rest of \molsturm,
\ie the \SCF and the Post-HF methods would just work
in a preliminary manner.
Many details regarding the numerical and algorithmic treatment
will most likely still need to be optimised thereafter,
such that high-level access to influence
all kinds of parameters of the \SCF scheme or the
diagonalisation algorithms are absolutely key.
Additionally such a new method would need to be tested and evaluated
towards their overall usefulness towards standard problem
of quantum-chemical modelling.
These tasks are usually both highly repetitive and again
require access into many layers of a quantum-chemistry program
to obtain the quantities to compare.
Aspects such as these motivate
the following overall design goals for the \molsturm project.

\paragraph{Enable rapid development:}
In the early stages of developing new quantum-chemical algorithms
it is often not clear how well these algorithms perform
or if they even meet the expected requirements.
Before worrying about making the algorithm fast,
one therefore first wants to know whether it even works.
A light-weight framework, which possesses the flexibility
to quickly combine or amend what is already implemented is very important for this.
The syntax of the resulting code should be high-level and intuitive,
resembling the physical formulae as much as possible.
To make the initial implementation easy for people
not entirely familiar with all tricks of the trade,
the details regarding the numerics and the linear algebra
should be mostly hidden in the code.
Especially in highly interdisciplinary subjects such as quantum chemistry
too often PhD students are rather unfamiliar to coding and numerics
and thus spend half a year to understand the clunky programs,
a year to implement the method,
just to find that it did not quite work that well.
Still influencing the algorithmic details
will in many cases be required at a later step.
Ideally this can be done by the means of changing mere parameters
directly from the user interface and
without changing the code very much,
such that it stays nice and clean for the next feature to be implemented.
A careful reader should have noticed that the \lazyten lazy matrix library,
described in the previous chapter,
covers many of the aspects mentioned here.
This is of course no surprise and explains why \lazyten has
become one of the key ingredients to \molsturm.
For some more details see \vref{sec:MolsturmPython}.
%
%
\begin{figure}
	\centering
	\includeimage{8_molsturm/molsturm_structure}
	\caption[Structure of the \molsturm package]
	{Structure of the \molsturm package. Shown are the five major
	modules of the package,
	along with the set of integrals accessible from \gint and the set of post-HF method,
	which can be used together with \molsturm.
	Only the modules inside the red box are part of \molsturm.
	The blue boxes are all external packages.
	The greyed-out boxes are planned, but not yet implemented.
	}
	\label{fig:structureMolsturm}
\end{figure}
\paragraph{Modular design with low code-complexity:}
The aspired flexibility of \molsturm as well as the intended
strong separation between high-level code describing algorithms
and low-level code dealing with the numerics,
necessarily calls for proper modularisation.
Even though our current design takes our experiences with many types
of basis functions into account,
it is very likely that we missed certain aspects,
which will make major restructuring unavoidable in the future.
To proactively account for this \molsturm consists of five small modules,
which are designed as layers, see figure \vref{fig:structureMolsturm}.
The top layer, ``\molsturm'', defines the application programming interface~(API),
by which other programs may control the flow of \molsturm or exchange data.
Unlike the other layers, which are mostly implemented in \cpp,
the \molsturm layer is mainly \python.
\gint, the \textit{general integral library},
provides a single link to multiplex between the supported integral calculation back ends.
\gscf implements a couple of \contraction-based \SCF schemes
following the general two-step Fock-update, coefficient/density-matrix-update structure,
we mentioned in section \ref{sec:SCFtakeaway}.
\gscf is written on top of \lazyten,
both to make use of its linear algebra abstraction
as well as the generality of the lazy matrix formalism
to work on dense, sparse and \contraction-based Fock matrices
under the same syntax.
Finally \krims is the library for common utility \textit{Krims}krams%
\footnote{German for ``odds and ends''}.
In our design we made sure
that dependencies are only downwards, never sideways or upwards,
to make it easy to replace libraries at a later point.
%
%
\paragraph{Plug-and-play implementation of new discretisations:}
When attempting to implement a new basis function type or an unusual discretisation technique
in existing quantum-chemistry packages,
there is one rather significant obstacle:
Implicit assumptions about the numerical properties of the employed basis
are scattered around the sometimes rather large codes.
Using the lazy matrix language of \lazyten,
we have achieved to centralise the basis function specifics as much as possible
at a single place,
namely the implementation of the \contraction expressions
of the integral lazy matrices.
This takes place in our integral interface \gint,
where all properties of the basis function type
as well as the precise back end implementation
regarding symmetries, selection rules, sparsity properties
or evaluation schemes are known and can be fully exploited.
In line with the final example presented in section \vref{sec:LazytenExamples},
the \SCF and post-\HF methods only need to care about the
integral lazy matrix objects,
being completely independent from the precise nature of the \contraction expression.
The result of these efforts is that switching from one implemented
basis function type to another can be achieved by merely passing
the corresponding string parameter.
All that effectively changes is the collection of lazy matrices,
which is exposed to the \SCF and all methods building on top
of the \SCF results.
Trying a new basis function type
or a new computational back end for the integral values
thus becomes really plug and play:
One implements the respective collection of lazy matrices and selects
it using the appropriate parameter.
For more details regarding this aspect see section \vref{sec:GscfGint}.
%
%
\paragraph{Easy interfacing with existing code:}
The evaluation and assessment of new quantum-chemical methods
necessarily implies that one needs to test their performance
towards standard problems of quantum chemistry.
This is especially true for new discretisation methods.
Implementing everything from scratch,
however, is a rather daunting task.
For this reason it is explicitly \emph{not} our goal
to create yet another fully-fledged quantum chemistry package
as well as the surrounding ecosystem around it.
Instead \molsturm is designed as a small package,
where both the full package as well as the individual modules
can be readily incorporated into other infrastructures
or used on their own for teaching and experimentation.
Overall our goal here is not to force a particular ``\molsturm-way'' upon
our users,
much rather provide well-documented and open interfaces,
with which it is easy to for them to interact with \molsturm
exactly how it fits there workflow best.
In this notion we want our \molsturm interface
to be flexible enough such that interacting
with third-party packages can be easily achieved,
thus building on the hundreds of man-years,
which went into the development of already existing quantum-chemistry codes,
and extend \molsturm beyond the scope originally intended.
For details see section \vref{sec:MolsturmPython}
as well as the examples in section \vref{sec:MolsturmExamples}.
%
%
\paragraph*{}
In the following sections we will discuss some of the
aforementioned design aspects in more detail.

\subsection{Self-consistent field methods and integral interface}
\label{sec:GscfGint}
In chapter \vref{ch:NumSolveHF} we looked at various ways to solve the
\HF equations, both with respect to different types of basis functions
for the discretisation as well as different \SCF algorithms.
One conclusion was that all \SCF schemes can be
condensed into a similar structure,
namely a two-step process,
where a Fock-update step and a coefficient-update or density-matrix-update step
repeat each other until convergence.
We already saw in the last example of section
\vref{sec:LazytenExamples},
that \lazyten is well-suited to support this.
In the example the Fock-update step could be expressed
by a call to the \update-function of the exchange and Coulomb lazy matrices
and the coefficient-update was
a diagonalisation using \texttt{eigensystem\_hermitian}.
For more complicated \SCF schemes, where the coefficient-update is more involved,
a \contraction-based ansatz still allows to express
this latter step only in terms of calls to the \contraction expression.
Taking this idea one step further the \SCF schemes
of \gscf do not need to see the individual terms of the Fock matrix,
but access to the \update function and \contraction expression
of a lazy matrix object representing the complete Fock matrix is sufficient.
This makes the algorithms of \gscf self-contained
and applicable to \emph{any} non-linear eigenproblem
with a structure similar to the \HF minimisation problem \eqref{eqn:HFMO}.
This is rather desirable,
because there are plenty of methods in electronic structure theory,
which can be thought of as modifications of the \HF problem.
Examples include the Kohn-Sham matrix~(see section \vref{sec:DFT})
arising in standard treatments of density-functional theory~(\DFT)
or additional terms in the problem matrix
arising from a modelling of an external field,
a density embedding or a polarisable embedding.

Overall the precise self-consistency problem to be solved by \gscf
is thus defined by the lazy Fock matrix object,
which is passed downwards from the upper layer \molsturm.
For building this lazy matrix
\molsturm inspects the method, which is selected by the user,
and appropriately combines the integral lazy matrices
representing the required one-electron and two-electron terms,
\ie kinetic, nuclear attraction, Coulomb and exchange for \HF.
Appropriately one would take an exchange-correlation term for \DFT
and additional terms for embedding theories.
Both is not currently available, however.

The integral lazy matrices are obtained from \gint,
which acts as broker presenting a common interface for all
basis function types and third-party integral back end libraries
towards the rest of the \molsturm ecosystem.
On calculation start \molsturm will take the discretisation parameters
supplied by the user and hand them over to \gint,
which --- based on these parameters ---
sets up the selected integral back end library
and returns a collection of lazy matrix integral objects.
For each basis type and back end the interface of the returned objects
will thus look alike, since they are all lazy matrices.
On call to their respective \contraction expressions, however,
the required computations will be invoked in the previously selected
integral back end.
In other words \gint itself does not implement any routine
for computing integral values at all,
but it just transparently redirects the requests.
Notice, that the precise kind of parameters needed by \gint
to setup the back end depends very much
on the selected basis function type.
For example a Coulomb-Sturmian basis requires the Sturmian exponent $\kexp$
and the selection of $(n, l, m)$ triples of the basis functions
whereas a contracted Gaussian basis requires the list of angular momentum,
exponents and contraction coefficients.

Right now contracted Gaussian and Coulomb-Sturmians
are in fact the only basis function types supported for discretisation in \gint.
For each of these at least two different implementations is available, however,
and adding more back end libraries or basis function types is rather easy.
Essentially one only needs to implement a collection of lazy matrices,
where the \contraction expressions initiates the appropriate
integral computations in the back end.
This collection then needs to be registered as a valid basis type
to \gint to make it available to the upper layers.
Adding preliminary support for the contracted Gaussian library
\libcint, for example, was added in just two days of work.
Notice, that the design of \gint would even allow all of this to be achieved
without changing a single line of code inside \gint itself,
since the call to the registration function could happen dynamically at runtime.
So one could implement a new integral back end in a separate shared library
and add it as needed in a plug-in fashion without recompiling \molsturm.

To summarise the responsibility for the \HF problem
has thus been effectively split between three different,
well-abstracted modules by the means of the lazy matrices of \lazyten.
\gint provides the interface to the integrals,
depending on the supplied discretisation parameters,
\molsturm builds the Fock matrix expression
according to the method selected by the user
and hands it over to \gscf to get the \SCF problem solved.

\subsection{\molsturm \python interface}
\label{sec:MolsturmPython}

The topmost layer of the \molsturm quantum-chemistry
package is our interface layer.
It provides helper functionality to
define the calculation parameters like the chemical system
or the basis type and basis set choices
and finally receives those from the user
to setup the calculation.
That is it obtains the integral lazy matrices
from \gint, builds the Fock matrix
as described above and starts the actual \SCF calculation.
The converged results from \gscf are afterwards
returned in a convenient data structure.

We chose to implement most of this interface layer
and especially the interface itself
in the scripting language \python.
Our reasoning for this is similar to the arguments
of the \pyscf authors already outlined in section \ref{sec:MolsturmRelated}.
By providing the required functionality to setup and drive
a \molsturm calculation from \python,
we avoid to define yet another ``input format'' and ``output format''
for quantum-chemical calculations.
Instead calculations can be initiated cleanly and flexibly
directly from a host script.
This can afterwards be used to post-process the results as well,
such that any kind of output parsing is not needed.
The whole calculation can be performed in a single script
from setup to analysis,
which makes the complete procedure much more transparent.
Moreover rather repetitive processes like
benchmarking a new method
can be easily automatised in this way.

To give the user full control over the complete \molsturm ecosystem
\emph{all} parameters for \gint, the \SCF algorithms of \gscf
as well as the employed linear solvers from \lazyten are forwarded
to the \python interface of \molsturm,
where they all can be directly accessed and changed.
These parameters include ways to influence which algorithms are
chosen by \lazyten for diagonalisation
or how \gint switches between the implemented \SCF solvers.
For returning the \SCF results back to the host environment \molsturm
heavily relies on \numpy arrays,
which have become the \textit{de facto} standard
for storing and manipulating matrices or tensors in \python.
A large range of standard \python packages,
which are commonly used for plotting or data analysis,
like matplotlib~\todo{cite}, scipy~\cite{Walt2011,scipyWeb}, pandas~\todo{cite}
similarly employ \numpy arrays as their primary interface.
Additionally by the means of interface generators like SWIG~\todo{cite}
\numpy arrays can be automatically converted to plain
\ccc arrays for calling more low-level \cpp, \ccc or \fortran code as well.

A \python interface comes in handy in the context of method development as well.
For example we explicitly support running \molsturm from an interactive
IPython~\todo{cite} shell,
such that one can immediately interfere with the progress of a calculation,
check assertions about intermediate results
or visualise these graphically with matplotlib~\todo{cite}.
This greatly reduces the feedback loop for small calculations
like during debugging.
If one uses \molsturm from a Jupyter notebook \cite{Jupyter},
one can even perform calculations and view plots
interactively from within a web browser.

For larger calculations \molsturm is able to archive the complete
calculation,
including \emph{all} \SCF results in
the widely adopted YAML~\cite{Ben-Kiki2009} or HDF5~\cite{HDF5Manual} formats.
In this way large calculations can be performed in advance
on a cluster or bigger computer,
then archived and transferred to a workstation machine
for analysis.
This can be again done in an interactive shell
with full access to the state of the calculation
as if it would have been performed locally.
Additionally this allows to restore an archived state
and continue in a different direction at a later point
building on results obtained previously
and without redoing everything from scratch.
On top of that \molsturm's archived state contains
the precise set%
\footnote{That is \emph{not} the parameters provided by the user,
but the post-processed parameters which were actually used
by the lower layers, amended for example by default values.}
of input parameters which were used to obtain the stored results.
This not only makes the archive self-documenting,
but additionally makes restarting the identical calculation
or a slightly amended calculation very easy.

Our aforementioned \numpy interface has already proven to be very helpful
to link to other third-party quantum chemistry codes to \molsturm.
For example \molsturm's \SCF can be used to start a
full configuration interaction~(FCI) calculation
in \pyscf~\cite{Sun2017}.
Recently support for computing excited state energies at \ADC(2),
\ADC(2)-x and \ADC(3)~\cite{Schirmer1982,Trofimov1999} level
with \adcman~\cite{Wormit2014} was added.
Both these links make use of the \python-\numpy interfaces
these third-party packages already offer and were realised in only a couple of days.
Notice, that these interfaces
are general enough to work both for \CS and \cGTO discretisations
and theoretically all basis function types which are implemented in \gint.

The aforementioned aspects will be demonstrated
in the context of practical examples in section \vref{sec:MolsturmExamples}.

\subsection{\molsturm test suite}
\label{sec:MolsturmTestSuite}

A very important subsidiary to a good software design is a good testing framework.
A test suite which is simple to execute,
fast and easy to expand not only allows to verify
that the current status of a piece of software is correct,
but it also allows to verify that all future changes do not break anything.
This naturally includes a potential adoption of the design towards future requirements.
A good test suite generally aids with any code refactoring,
since all changes can be performed in a sequence of many small steps,
verifying the correctness of the software on the way.

For this reason \molsturm comes with an extensive test framework
with roughly four types of tests.
Firstly there are \newterm{unit tests},
which test the functionality of a single function
or code unit in a couple of hard-coded examples.
Further we have \newterm{functionality tests},
which test a larger portion of code and are meant to ensure that
the results of \molsturm agree between different versions.
Thirdly the \newterm{reference tests} compare
the results of \molsturm to other quantum-chemistry packages.
Especially in \lazyten we furthermore make use of yet another type of tests,
namely so-called \newterm{property-based tests}.
This testing technique uses the expected properties of a code unit
to randomly generate test cases and to verify the result as well.
On failure the generated test cases are simplified until the most simple,
failing test case is found.
This is very helpful
to reduce the human aspect in testing
and finding the actual issue during debugging.

Next to combining various different types of tests,
it is very important that running the tests by itself is hassle-free.
Only in this way they are actually used.
In \molsturm we therefore employ the \newterm{continuous integration}
service offered free of charge by Travis CI GmbH for open source projects:
Whenever a new commit is made to our github repository,
a set of virtual machines start automatically
in order to checkout and build \molsturm completely from scratch
in a few typical build configurations.
Afterwards the test suite is automatically executed and
all output generated by the test suite displayed.
In this way even people, who are unfamiliar with all details of \molsturm
can test their changes thoroughly,
which encourages code contributions.
Additionally this gives us \molsturm developers
the chance to easily make sure that no untested code enters the stable source branch,
since only if the continuous integration testing passes,
a commit to the stable branch is allowed.

One might argue that such a continuous integration system only
achieves its purpose if users committing new code
furthermore write the accompanying tests to check its validity.
For this reason we try to make it simple to add new tests
by providing tooling to automate this process as well.
For example in order to add a new reference test for a new feature
or a corner case, where a bug was discovered,
one only needs to add a small configuration file to a special directory.
Afterwards one only needs to call a \python script,
which picks up the configuration file,
reads the desired test case and calls the external third-party reference
quantum-chemistry program (currently ORCA~\cite{ORCA})
to compute the required data.
From the next time the \molsturm test suite is executed,
this additional reference test will be part of the test suite as well.

Another way we employ to make sure that most of \molsturm's code
is indeed tested
is a measure called \newterm{coverage analysis}.
Roughly speaking this method inserts special checkpoints during the compilation
of a program,
which allow to retrace which code paths have been executed
and which have not.
In combination with our automatic continuous integration builds,
we use this to check automatically which parts of the code have been touched
when the test suite was executed,
\ie which parts of \molsturm are covered by the test suite.
Ideally one would keep test coverage close to $100\%$,
implying that literally every line of \molsturm was tested.
In practice in most modules of \molsturm we currently achieve
between $80\%$ and $90\%$ coverage.
Notice that coverage analysis is more powerful than just detecting
untested code paths.
For example it allows to find hot spots,
\ie parts of the code executed very often,
or dead code, which is never executed.
Similar to a pass of the continuous integration builds,
we currently enforce that \molsturm's coverage may not decrease
by more that $0.5\%$ each time code is merged into the stable branch.
This makes sure that most of \molsturm's code really gets tested
each time new features are added.
