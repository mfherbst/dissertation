\section{\molsturm program design}
\label{sec:MolsturmDesign}

As mentioned above the main target for the current design of \molsturm
is to yield a framework,
which supports notions towards novel quantum-chemical methods,
including methods where unusual discretisation approaches
or new types of basis functions are employed.
Ideally for this the design supports adding
new basis functions 
in a plug-and-play kind of fashion,
such that the potential user implements a minimal interface
towards his integral library and the rest of \molsturm,
\ie the \SCF and the Post-HF methods would just work.
Naturally many aspects regarding the numerical and algorithmic
details will still need to be optimised thereafter,
such that overall flexibility and high-level access towards
all kinds of parameters of the \SCF scheme or the
diagonalisation algorithms are absolutely key.
Additionally such a new method would need to be tested and evaluated
towards their overall usefulness towards standard problem
of quantum-chemical modelling.
Such tasks are both highly repetitive and often requires
access into many layers of a quantum-chemistry program
to obtain the quantities to compare.
Aspects such as these motivate
the following overall design goals for the \molsturm project.

\begin{itemize}
\item \textbf{Enable rapid development:}
In the early stages of developing a new quantum-chemical algorithms
it is often not clear how well these algorithms perform
or if they even meet the expected requirements.
Before worrying about making the algorithm fast,
one first wants to know whether it even works.
For this a light-weight framework which possesses the flexibility
to quickly combine or amend the already implemented
functionality is very important.

phd should not spend a year to implement something which might not work
need flexiblity to try things
code should be easy and close to the physical formulae
%
%
\item \textbf{Simplify switching between discretisations:}
Common ground for experimentation
Implies that simple switching between solver algorithms
separation of algorithm and numerics

One of the goals of molsturm is to support the numerical requirements of many
types of basis functions and to provide a common ground for experimentation. A key
ingredient to achieve this is a contraction-based SCF procedure in the lazy matrix
language of lazyten. 
As will be described in more detail further down
allows to separate the SCF implementation very well from the details of the contraction
expression of the Fock matrix. This in turn can be freely varied as needed from basis
function type to basis function type. As a result the SCF code is fully agnostic to the
type of basis function used.
On top of this molsturm provides a powerful python interface which allows to easily

%
%
\item \textbf{Easy interfacing with existing code:}
Use what already exists in other python packages or in other quantum-chemistry packages
No full-fletched program intended
quickly get what is needed

Furthermore well-documented and open interfaces
as well as compliance with the available standards
allow easy integration of other frameworks to extend
the functionality of a package even beyond the scope
which was intended in the first place.
Only took order of days to interface with \pyscf and \adcman
high level interfaces.


Additionally this interface makes it
convenient to re-use existing software modules
together with \molsturm's \SCF.
In this manner we have already managed to link \molsturm to \pyscf~\cite{Sun2017}
for performing full configuration interaction~(FCI) calculations
and recently \adcman~\cite{Wormit2014}
for computing excited state energies at \ADC(2),
\ADC(2)-x and \ADC(3)~\cite{Schirmer1982,Trofimov1999} level.


The careful reader might have noticed that a well-designed interface
might not only facilitate rapid development of new algorithms
but also prevent one from the need to re-implement the wheel
and much rather exploit the code which has already has been written
for one's purposes.

Easy data retrieval and post processing (see examples)
Support iterative approach to problems by archival
and storage of computational parameters
%
%
\item \textbf{Support iterative approach to quantum-chemical modelling:}
Iterative process

Especially the ability to archive a large portion of the calculation
furthermore allows to exploit previous results when performing
further calculations as well as delaying the analysis
to a later point when \eg more knowledge about the
problem has been obtained to decide what exactly to look at.
%
feedback loop
Firstly it makes it easy to interactively work with \molsturm
from a shell. This reduces the feedback loop for small calculations
or during debugging.  If one uses \molsturm from a Jupyter notebook \cite{Jupyter},
one can even perform calculations and view plots interactively from within a web browser.
\end{itemize}



%----
Conceptionally an SCF algorithm is entirely independent of the type of basis function.
One could think of it very much as a numerical technique to solve
an non-linear eigenvalue problem by linearisation.
Once the SCF orbitals have been obtained,
the remainder of a calculation (\eg a Post-HF method)
can be formulated entirely in the SCF orbital basis
and without any reference to the underlying type of basis functions.
As such it should be possible to design a quantum chemistry package,
which apart from the integral backend itself is entirely independent
of the basis function types which are implemented.

Once the \SCF orbitals have been obtained,
the remainder of a calculation, \eg a Post-\HF method,
can be formulated entirely in the \SCF orbital basis
and without any reference to the underlying basis functions.
Therefore a basis-function independent SCF scheme automatically
leads to basis-function independent Post-HF methods as well.
%----

Achieving this has several advantages.
First of all it naturally implies that trying out some new basis functions is very easy,
since most of the code already exists and can be reused.
Just the integral computation by itself needs to be adapted.
Secondly comparing different basis function types can occur in a fair setting,
since for all types of basis functions the algorithms are optimised to a similar level.
Thirdly it even allows for a fair comparison between different integral backends,
\eg different GTO libraries.

Last but not least the ability to treat different kinds of basis functions
in the same framework simplifies the construction of hybrid basis sets,
where possibly numerical basis functions and GTOs or STOs are combined.
Similarly one could employ the strengths of multiple backends for the same type of basis function
in the sense that one mixes and matches different backends such that one can exploit
the advantages of both implementations best.





\subsection{Program structure}
% TODO here focus on the how
\begin{figure}
	\centering
	\includeimage{8_molsturm/molsturm_structure}
	\caption{Structure of the \molsturm package: Shown are the five modules of the package,
	along with the set of integrals accessible from \gint and the set of post-HF method,
	which can be used from \molsturm. The greyed-out parts are not yet implemented.
	Only the modules inside the red box are part of \molsturm. The blue boxes are all external packages.}
	\label{fig:structureMolsturm}
\end{figure}

Due to goals flexibility is key.
Very likely parts of the code will need to be adapted later



As can be seen in fig. \ref{fig:structureMolsturm} this is realised
by a modular design,
where each of the five major modules has a very
distinct responsibility.
Most importantly only the integral module \gint
exploits the properties of the type of basis functions.
\gint for example decides the sparsity structure of the
repulsion integrals or the Fock matrix.
This structure is encoded inside the lazy matrices,
which \gint exposes to the SCF algorithms inside \gscf.




General overview the importance of \lazyten

%----
\lazyten is the linear algebra interface of \molsturm.
It not only implements the lazy matrix datastructures,
which define the common interface of \gint and \gscf,
but further contains code to make standard external
iterative or direct solver implementations available
from a lazy matrices-based setting.

Similarly the eigensolvers can be accessed from \gscf via a common interface,
which abstracts the precise algorithm and allows \lazyten to make an automatic
choice by looking at the precise structure of the Fock matrix at hand.
%----


Typically one first performs a self-consistent field calculation,
either by solving the Hartree-Fock or the Kohn-Sham equations.
The obtained self-consistent solution is then used for example in
linear response calculations or Post-HF methods.
It is important to note that these steps
typically do not need any knowledge of the underlying basis function type
at all, since they are formulated in terms of SCF orbitals only.
The \molsturm program package therefore concentrates
on a basis-function independent SCF code
with interfaces to simplify using the resulting SCF solution
in third-party code for further processing.

From the point of view of \gscf,
on the other hand,
the lazy matrices for all types of basis functions look alike.
In other words by the means of the lazy matrices
the algorithms in \gscf
can be written in such a high-level manor,
that they are entirely independent of the precise matrix structure.
Consequently they are independent of the choice of basis function type as well.

The lower layers \lazyten and \krims provide
the lazy matrix implementation as well as other utilities,
which are needed to pass information between the individual modules.
\lazyten furthermore contains an interface,
which allows lazy-matrix based algorithms like the ones in \gscf to
call standard iterative solver implementations.


\subsection{The interplay of self-consistent field algorithm and integral library}
About interplay between \gint and \gscf

Conceptionally an SCF algorithm is entirely independent of the type of basis function.
One could think of it very much as a numerical technique to solve
an non-linear eigenvalue problem by linearisation.

In chapter \vref{ch:NumSolveHF} we looked at various ways to solve the
\HF equations both with respect to different types of basis functions
for the discretisation as well as different \SCF algorithms.
Our conclusion was firstly that all \SCF schemes can be
condensed into the similar structure of a two-step process,
where a Fock-update step and a coefficient-update or a density-update step
repeat each other until convergence.
Secondly we mentioned that a \contraction-based ansatz could result in \SCF schemes,
which are agnostic to the type of basis function used.
The lazy matrix formalism and the corresponding \lazyten library,
introduced in the previous chapter,
provided ways to express \contraction-based algorithms at a high level.
Overall this means that the details of the \contraction implementation,
\ie the part deviating between different types of basis functions,
could be abstracted from the implementation of the \SCF algorithm
and vice versa.
We already briefly mentioned this in a concluding example
in section \vref{sec:LazytenExamples}.

%----
lazyten layer
An additional advantage of such a layer would be that
modifications of the system matrix can be transparently expressed
to the iterative schemes.
For example adding extra terms to the Fock matrix
describing an electric field or a polarisable embedding
or other contributions does not really require
any change to the \SCF code at all.
A good layer of abstraction between the actual \SCF algorithm
and the implementation of the matrix-vector contractions
is therefore highly desirable to enable flexibility on both sides.

need flexibility in matrix expressions in real-world application
like \SCF (extra terms of varying complexity from external field,
polarisable embedding, fragment approaches, and so on)
non-linearity of Coulomb and Exchange
would be nice to transparently express this
% ----

\todoil{Fock matrix $\Leftrightarrow$ Kohn-Sham matrix $\Leftrightarrow$ Problem matrix
to make clear that \gscf is not only for HF problems }


Similar to the \molsturm interface layer when it comes to Post-HF methods,
\gint does not implement any routine for computing the integrals.
Instead it just acts as a broker,
which presents a common interface for all available basis function types
and third-party integral backend libraries.

When a calculation starts,
\molsturm passes \gint the set of parameters,
which are relevant for the selection and setup of the integral backend,
like for example the Coulomb-Sturmian exponent or the Gaussian basis set information.
In return \gint provides \molsturm with a collection of lazy matrices,
where each lazy matrix represents a single integral for this
type of basis functions.
For example the nuclear attraction matrix, the kinetic operator matrix,
the coulomb matrix and the exchange matrix each exist as separate
lazy matrix objects.
These integral objects may then be combined
in an arbitrary manor to form the Fock matrix or Kohn-Sham matrix
expression by just forming linear combinations.
The resulting Fock matrix expression is then typically passed onto \gscf,
where the SCF problem is solved.

The generality of the lazy matrices allows the interface of \gint
to be entirely independent of the structure
which is used to represent the integral data internally.
This implies that all code inside \molsturm,
which works with the integral objects,
hence becomes independent of the way the integral data is represented
or how the evaluation of the \contraction function is actually performed.
\gint may freely choose the scheme for evaluating a matrix-vector
product or for example the sparsity structure which is used to
represent the data of the integral matrix
without this having any impact towards other parts of \molsturm.

Using lazy matrices furthermore has an advantage for
dealing with the non-linearity of the coulomb and exchange matrices:
The lazy matrix formalism of \lazyten provides the possibility
to implement a special \update function,
which can be used to update internal state of a lazy matrix.
The coulomb and exchange lazy matrices
may use this function to retrieve a new set of coefficients from an
SCF algorithm and update
their internal state accordingly.
As we will discuss in the next section \gscf makes frequent use of this feature.

Currently \gint only offers two types of basis functions,
namely Gaussian integrals and atomic Coulomb-Sturmians,
both available in at least two different implementations.
For example Gaussian integrals for \gint are available from either one of 
\libint by Valeev et al.\cite{Libint2,Libint2_231}
or \libcint by Sun et al.\todo{cite} 
under a common interface.
The design of \gint makes it furthermore very simple to extend the types of integrals
available in \molsturm:
The function calls which compute the integral values only need to be wrapped
inside lazy matrix objects and the resulting integral collection needs to be registered
with \gint.
For example the support for \libcint was added in just two days of work.

Note that this does not even require changing a single line of code inside \gint.
One could achieve this by linking the library into \molsturm at compile time.

\gscf assumes two-step \SCF process,
which is prefectly supported by the lazy matrices returned by \gint
by their \update function.

Currently all algorithms which are implemented in \gscf are coefficient-based SCF algorithms.
This is not strictly speaking required by the library,
but it has the advantage that for some basis function types
the computational scaling of the \contraction-function
of the Fock matrix expression can be reduced by an order of magnitude.
An example are the Coulomb-Sturmians.
\todoil{Maybe go into this a little in the previous sections and refer up}
Furthermore the density-matrix based algorithms
we have encountered so far could be reformulated as coefficient-based schemes
or were easily approximated to work as such.
For example we have implemented a variant of the original ODA,
which is suitable for a coefficient-based setting by truncating
the history of SCF steps considered in order to compute the optimal damping.
Talk about the implemented algorithms

be sure to emphasise that all lazyten code could be still used for dense computations

point out that parameters for \lazyten, eg with respect to the solvers
can actually be passed easily from the high-level \python interface of \molsturm

\subsection{\molsturm \python interface}

Right now very simple and not efficient
Refer to examples as needed

For example the Full-CI interface to \pyscf was realised in only two days,
but still is general enough to work for Sturmians GTOs and theoretically
all basis function types which are implemented in our integral backend.
\todoil{Change to also mention CC if we get there}
In another proof-of-concept project of ours we just managed to
implement ADC(2)-x on top of \molsturm in less than 10 days in \python.


The topmost \molsturm layer handles calculation set-up 
(e.g., definition of molecules, basis set choice, choice 
of SCF-calculation scheme, et cetera), as well as interfacing 
to the outside world. \molsturm can be controlled in two ways: 
directly as a \cpp library, which is most convenient if it is to 
be called from within a quantum chemistry code written in \cee, \cpp, 
or \fortran; or it can be controlled through a \python interface.

We purposefully do not define a new ``input format'': calculations are 
controlled more cleanly and flexible by simply using
\python scripts (or calling it directly from a host quantum 
chemistry package) to drive calculation.
By calling simple interface functions, an SCF calculation can be set
up, and the appropriate integrals passed on to Post-HF calculations
if desired. The next section shows examples of how this is done.

Refer to the ideas of \pyscf
(input format)

Secondly this gives the user full flexibility
of how to embed \molsturm in his or her workflow.
From the \python interface, all data from \molsturm is available
in plain \numpy arrays, so the user can easily do
any kind of standard processing from \python
after or during a calculation.

python packages and for example jupyter


Furthermore \numpy arrays have become the \textit{de facto} standard
for storing and manipulating matrices or tensors in \python.
All third-party quantum chemistry codes which
offer a \python interface
either use \numpy arrays themselves or
provide utility functions to convert to and
from \numpy arrays.
\todoil{check if this is true and cite them}
The same is true for typical \python packages used for plotting or
data manipulation (matplotlib, scipy, pandas).

Thirdly by the means of interface generators
like SWIG \todo{cite} \numpy arrays can be converted to plain
\cee arrays for calling \cpp, \cee or \fortran code,
such that even low-level libraries can be employed
from \numpy arrays.



\subsection{Programming guidelines and paradigms}



Testing
modularisation
combination of high-level and low-level code

A very important subsidiary to good software design is a flexible testing framework.
A test suite which is simple to execute, fast and easy to expand not only allows to verify
that the current status of a piece of software is correct,
but it also allows to verify that all future changes do not break anything.
This includes of cause the potential adaption of the design in the future,
which might involve changing any of the already existing interfaces.
A strong test suite aids with this procedure,
since one can perform these changes in a sequence of many small steps,
verifying the correctness of the software on the way.

For this reason \molsturm comes with an extensive test framework
with roughly four types of tests.
Firstly there are \term{unit tests},
which test the functionality of a single function or code unit in a couple of hard-coded examples.
Further we have \term{functionality tests},
which test a larger portion of code and are meant to ensure that
the results of \molsturm agree between different versions.
Thirdly the \term{reference tests} compare
the results of \molsturm to other quantum-chemistry packages.
Especially in \lazyten we furthermore make use of yet another type of tests,
namely so-called \term{property-based tests}.
This testing technique uses the expected properties of a code unit
to randomly generate test cases and to verify the result.
On failure the generated test cases are simplified until the most simple,
failing test case is found.
This is really helpful for debugging and in order to reduce the human aspect in testing.

Next to combining various different types of tests
other key principles in the design of our test suite were that our tests should be simple
to execute and take only a couple of minutes.
This not only makes it easier to motivate others to use the tests, too,
but it also allows to fully automate the whole testing process as well.
\todoil{I feel we should explicitly mention github and Travis-CI to show them some credit for this awesome work.}
In our case any commit to our repositories starts up a couple of virtual machines,
which build \molsturm and run the test suite for a couple of common compilers and
build configurations.
A commit into the stable source code branch is only accepted if the test suite passes.

In our test suite even the work of adding a new test is somewhat automated.
For example in order to add a new reference test for a new feature
or a case where a bug was discovered,
one simply adds a small configuration file to a special directory,
which defines the testing parameters.
A \python script, which is part of the test suite,
then automatically executes the third party program and extracts the reference results in a format,
which is understood by the \molsturm test suite.
When the test suite is executed all such reference results are read and
\molsturm is executed and tested for each of them.

\todoil{Mention test coverage ???}

\todoil{We probably should not keep this next paragraphs here}
On the side of the \molsturm code we employ \term{assertive programming} to assure that
\molsturm crashes with a very detailed backlog whenever an unexpected behaviour happened.
By the means of a dual build system setup, we achieve that a Debug version
(including heavy assertive checks) and a Release version
(without heavy assertive checks) are compiled side-by-side.
This allows to use the Debug version with a lot of assertions,
potentially even in the inner loops,
to be used for trial runs and the Release version with less assertions for productive runs.
Switching between Debug and Release from \molsturm's python interface is very simple and
only requires to recompile a few files,
since in normal build conditions Release and Debug have already been built.

By the means of checkpointing one could further use the Release version to get an erroneous
part of \molsturm and the Debug version to step-by-step test what goes wrong.
The detailed traceback on failure of an assertion can then be used to analyse the problem quickly.
