\section{Many-body Schrödinger equation}
\label{sec:ManyBodyTISE}
\defineabbr{BO}{BO\xspace}{Born-Oppenheimer approximation}
\nomenclature{$\Psi$}{State of a (many-body) quantum system,
	typically the \emph{exact} ground state solution to the many-electron,
	electronic time-independent Schrödinger equation.}
\nomenclature{$\Nelec$}{Total number of electrons.}
\nomenclature{$M$}{Number of nuclei.}
\nomenclature{$\Op{H}_{\Nelec}$}{Electronic Hamiltonian
	for a $\Nelec$-electron system, see section \ref{sec:BO}.}
\nomenclature{$\vec{x}$}{Vector in $\R^{3 \Nelec}$,
which typically specifies the positions of all electrons of the system.}
\nomenclature{$\vec{r}$}{Vector in $\R^3$, which specifies the position of an electron in space.}
\nomenclature{$\mat{M}$}{Matrix with elements denoted as $M_{ij}$.}
\nomenclature{$\mathcal{I}$}{Index set.}

Let us consider a chemical system consisting of $M$ nuclei and $\Nelec$ electrons.
We take the nuclei to be located at mass-scaled\footnote{
	If $\vec{\tilde{R}}_A$ is the Cartesian coordinate
	of the $A$-th nucleus with mass $M_A$, then
	the mass-scaled coordinates are given as
	$\vec{R}_A = \sqrt{M_A} \, \vec{\tilde{R}}_A$.
} coordinates
$\{\vec{R}_A\}_{A = 1, 2, \ldots, M} \subset \R^3$
with corresponding charges
$\{Z_A\}_{A = 1, 2, \ldots, M}$.
The electron positions are denoted by the (Cartesian) coordinates
$\{\vec{r}_i\}_{i = 1, 2, \ldots, \Nelec} \subset \R^3$.
Following the correspondence to classical mechanics (see section \vref{sec:IntroQM})
we can construct the many-body Hamiltonian
on the Hilbert space $L^2(\R^L, \C)$ with dimensionality $L = 3M+3\Nelec$ as
\begin{equation}
	\Op{H}^\text{MB} = \Op{T}_e + \Op{T}_n + \Op{V}_{nn} + \Op{V}_{ne} + \Op{V}_{ee}.
	\label{eqn:ManyBodyHamiltonian}
\end{equation}
In this expression we introduced the
nuclear-nuclear, electronic-electronic and nuclear-electronic
Coulombic interaction potentials
\begin{align}
	\label{eqn:ManyBodyHamiltonianPotential}
	\Op{V}_{nn} &= \sum_{A=1}^M \sum_{B=A+1}^M
		\frac{Z_A Z_B}{\norm{\vec{R}_A - \vec{R}_B}_2}, &
	\Op{V}_{ee} &= \sum_{i=1}^{\Nelec} \sum_{j=i+1}^{\Nelec}
		\frac{1}{\norm{\vec{r}_i - \vec{r}_j}_2}, \\
	\nonumber
	\Op{V}_{ne} &= - \sum_{A=1}^M \sum_{i=1}^{\Nelec} \frac{Z_A}{\norm{\vec{R}_A - \vec{r}_i}_2},
\end{align}
respectively.
Furthermore we used the electronic and nuclear kinetic energy operators
\begin{align}
	\label{eqn:ManyBodyHamiltonianKinetic}
	\Op{T}_e &= -\frac12 \sum_{i=1}^{\Nelec} \Delta_{\vec{r}_i}, &
	\Op{T}_n &= -\frac12 \sum_{A=1}^M \Delta_{\vec{R}_A},
\end{align}
with the shorthand
\[ \Delta_{\vec{q}} = \sum_{\alpha=1}^3 \frac{\partial^2}{\partial q_\alpha^2} \]
for the Laplace operator with respect to particle coordinates $\vec{q}$.
If we take the domain $D(\Op{H}_\text{MB}) = H^2(\R^L, \C)$
this operator can be made self-adjoint~\cite{Kato1951}.
It is furthermore bounded below~\cite{Kato1951}
with a couple of discrete states below the essential spectrum.

The operator $\Op{H}^\text{MB}$ is the fundamental object
the field of quantum chemistry investigates.
Its properties allow for a full
(non-relativistic) quantum-mechanical description
of a chemical system.
This includes important properties like stable chemical structures
or reactivity, with respect to other molecules as well as external potentials.
As discussed in section \vref{sec:SpectralTakeAway}
a consequence of the laws of thermodynamics is,
that in many cases one already gets
a reasonable idea about the chemical properties of matter
if only the lowest-energy, discrete eigenstates of the relevant
many-body Hamiltonian $\Op{H}_\text{MB}$ are determined.

Let us use the vectors $\vec{x} \in \R^{3\Nelec}$ and $\vec{X} \in \R^{3M}$, defined as
\begin{align}
	\rtp{\vec{x}} &\equiv \left(\rtp{\vec{r}_1}, \rtp{\vec{r}_2}, \ldots, \rtp{\vec{r}_{\Nelec}}\right),
	&
	\rtp{\vec{X}} &\equiv \left(\rtp{\vec{R}_1}, \rtp{\vec{R}_2}, \ldots, \rtp{\vec{R}_{M}}\right),
	\label{eqn:DefAllCoords}
\end{align}
to refer to all electronic or all nuclear coordinates, respectively.
Taking $I$ to denote an appropriate multi-index of quantum numbers,
our problem from the previous paragraph can be reformulated
as finding those eigenstates $\Psi^\text{MB}_I \in H^2(\R^L, \C)$
with lowest corresponding energies $E^\text{MB}_I \in \R$
by the means of solving the time-independent Schrödinger equation
\begin{equation}
	\Op{H}^\text{MB} \Psi_I^\text{MB}(\vec{X}, \vec{x})
	= E_I^\text{MB} \Psi_I^\text{MB}(\vec{X}, \vec{x}).
	\label{eqn:TISEManyBody}
\end{equation}
Solving this equation analytically is not possible in general.
Already for the Helium atom, a 3-body problem, clever approximations are needed
to get anywhere~\cite{Hylleraas1929}.
But even numerically \eqref{eqn:TISEManyBody} is intractable to solve
without further approximations.

Let us illustrate this claim by an example.
In water, \ce{H2O}, we have $3$ nuclei and $10$ electrons.
The dimensionality%
\footnote{Some of the $39$ degrees of freedom can be factored out,
namely the $3$ overall translations of the molecule.
This does not change the overall picture very much and we will ignore
this possibility in our discussion.}
of the problem is thus $L = 3 \cdot 13 = 39$.
In the numerical approach we introduce in section \vref{sec:Projection}
the evaluation of the inner product
\begin{equation}
	\braket{\Psi}{\Phi} \equiv \int_{\R^{3M}} \int_{\R^{3\Nelec}}
		\cc{\Psi}(\vec{x}, \vec{X}) \Phi(\vec{x}, \vec{X})
	\D \vec{x} \D \vec{X}
	\label{eqn:MBInnerProduct}
\end{equation}
between two functions $\Psi$ and $\Phi$ from the
underlying Hilbert space $L^2(\R^L, \C)$ appears rather prominently.
Most notably the computation of the sesquilinear form $a(\slot,\slot)$
in order to build the discretisation matrix in \eqref{eqn:DiscretisedEigenproblem}
boils down to computing such integrals.
The numerical evaluation of \eqref{eqn:MBInnerProduct}
implies a sampling of the $L$-dimensional space $\R^L$ in some way or another.
Even for an extremely sophisticated discretisation method
or a well-designed quadrature scheme we will probably need of the order of
$10$ sampling points per dimension.
For a 39-dimensional problem, like our water molecule,
this makes on the order of $10^{39}$ sampling points overall.
If we want a single integration to finish within the lifetime of a human being,
say $100$ years,
the evaluation of the
integration kernel $\Psi(\vec{x}, \vec{X}) \Phi(\vec{x}, \vec{X})$
may take no more than some $10^{-30}$ seconds,
which is impossible due to the physical limitations inside a general purpose computer.

Certainly one could probably find even more clever methods in some cases,
but the example illustrates the so-called \newterm{curse of dimensionality} rather well.
For a general quantum-chemical investigation of matter
one needs to develop approximate methodologies.

\section{Born-Oppenheimer approximation}
\label{sec:BO}
The masses of electrons and nuclei differ by orders of magnitude.
The ratio between the mass of a proton and the electron masses
is already around $1836$ and this ratio increases
further across the table.
Already for the elements of the second period,
this value is at least of the order of $10^4$.
This justifies an approximative treatment,
where we assume the motion of the electrons
and the motion of the nuclei to happen at different timescales.

For this let us consider
a simplified version of \eqref{eqn:ManyBodyHamiltonian} at first,
namely the \newterm{electronic Hamiltonian}
\[
	\Op{H}^\text{elec} \equiv \Op{H}^\text{MB} - \Op{T}_n
	= \Op{T}_e + \Op{V}_{ne} + \Op{V}_{ee} + \Op{V}_{nn}.
\]
This operator is constructed from the full many-body Hamiltonian
by neglecting the nuclear kinetic energy operator $\Op{T}_n$ completely.
Introducing the short hand notation
\nomenclature{$r_{ij}$}{Short hand for $\norm{\vec{r}_i - \vec{r}_j}_2$.}
\begin{align*}
r_{AB} &\equiv \norm{\vec{R}_A - \vec{R}_B}_2, &
r_{iA} &\equiv \norm{\vec{r}_i - \vec{R}_A}_2, &
r_{ij} &\equiv \norm{\vec{r}_i - \vec{r}_j}_2, &
\end{align*}
we can write it as
\begin{equation}
	\Op{H}^\text{elec}
	= - \frac12 \sum_{i=1}^{\Nelec} \Delta_{\vec{r}_i}
	- \sum_{A=1}^M \sum_{i=1}^{\Nelec} \frac{Z_A}{r_{iA}}
	+ \sum_{i=1}^{\Nelec} \sum_{j=i+1}^{\Nelec} \frac{1}{r_{ij}}
	\  + \  %
	\sum_{A=1}^{M} \sum_{B=A+1}^{M} \frac{Z_A Z_B}{r_{AB}}.
	\label{eqn:ElectronicFullHamiltonian}
\end{equation}
Even though $\Op{H}^\text{elec}$ still depends on the nuclear coordinates $\vec{X}$,
one could interpret the elements of the vector
$\vec{X}$ not as coordinates,
but much rather as parameters for the potential operators $\Op{V}_{ne}$ and $\Op{V}_{nn}$.
Physically this means that $\Op{H}^\text{elec}$ describes a chemical system
where the nuclei are clamped at well-defined points in space.
Sometimes we will write $\Op{H}^\text{elec}(\vec{X})$
in order to make the parametrisation of $\Op{H}^\text{elec}$ with respect to $\vec{X}$
visible.

\newcommand{\Iel}{I_\text{e}}
\newcommand{\Inu}{I_\text{n}}
Without going into details at the moment,
let us assume that $\Op{H}^\text{elec}$ becomes self-adjoint
inside a suitable domain.
With appropriate multi-indices $\Iel$
we can thus find its eigenpairs $(E^\text{elec}_{\Iel}, \Psi^\text{elec}_{\Iel})$
via the \newterm{electronic Schrödinger equation}
\begin{equation}
	\Op{H}^\text{elec}(\vec{X}) \Psi^\text{elec}_{\Iel}(\vec{X}, \vec{x})
	= E^\text{elec}_{\Iel}(\vec{X})
		\Psi^\text{elec}_{\Iel}(\vec{X}, \vec{x}).
	\label{eqn:ElectronicSchrödinger}
\end{equation}
Originating from the dependence of $\Op{H}^\text{elec}(\vec{X})$
towards the nuclear coordinates,
we can think of the resulting \newterm{electronic energies}
$E^\text{elec}_{\Iel}(\vec{X})$
and \newterm{electronic wave function}s $\Psi^\text{elec}_{\Iel}(\vec{X}, \vec{x})$
to be dependent on $\vec{X}$ as well.
Typically one uses the term \newterm{electronic state}
to refer to $\Psi^\text{elec}_{\Iel}(\vec{X}, \vec{x})$.

With the electronic states at hand we are able to formulate
the framework of the \newterm{Born-Oppenheimer approximation},
which consists of the following two assumptions:
\begin{itemize}
	\item Each eigenstate of \eqref{eqn:ManyBodyHamiltonian} may be written
		by a factorisation
	\begin{equation}
		\Psi^\text{MB}_I(\vec{X}, \vec{x}) \equiv \Psi^\text{MB}_{\Iel\Inu}(\vec{X}, \vec{x})
		\simeq \Psi^\text{elec}_{\Iel}(\vec{X}, \vec{x})
		\Psi^\text{nuc}_{\Inu}(\vec{X}),
		\label{eqn:BOFactorisation}
	\end{equation}
	where the multi-indices are related by $I \equiv (\Iel, \Inu)$.
	$\Psi^\text{elec}_{\Iel}(\vec{X}, \vec{x})$ is a solution
	to the electronic Schrödinger equation \eqref{eqn:ElectronicSchrödinger}
	and the \newterm{nuclear wave function}
	$\Psi^\text{nuc}_{\Inu}(\vec{x})$ is yet to be determined.
	%
	\item The factorisation \eqref{eqn:BOFactorisation} satisfies the property%
	\footnote{%
		More precisely what we assume is that the nuclear kinetic energy
		operator $\Op{T}_n$ projected onto the basis formed by
		all electronic states $\Psi^\text{elec}_{\Iel}(\vec{X}, \vec{x})$
		is diagonal with all elements equal to $1$.
		See \cite{Baer2006} or \cite{WikipediaBornOppenheimer} for details.
	}
	\begin{equation}
		\Op{T}_n \Psi^\text{MB}_{I}(\vec{X}, \vec{x})
		\simeq \Op{T}_n \left( \Psi^\text{elec}_{\Iel}(\vec{X}, \vec{x})
		\Psi^\text{nuc}_{\Inu}(\vec{X}) \right)
		\simeq \Psi^\text{elec}_{\Iel}(\vec{X}, \vec{x})
		\left(\Op{T}_n \Psi^\text{nuc}_{\Inu}(\vec{X}) \right).
		\label{eqn:BONuclearDerivative}
	\end{equation}
\end{itemize}
By plugging ansatz \eqref{eqn:BOFactorisation} into \eqref{eqn:TISEManyBody}
we can simplify
\begin{align*}
	0 &=
	\left( \Op{H}^\text{MB} - E^\text{MB}_{I} \right)
	\Psi^\text{MB}_{I}(\vec{X}, \vec{x}) \\
	&\stackrel{\eqref{eqn:BOFactorisation}}{\simeq}
	\left( \Op{H}^\text{elec} + \Op{T}_n - E^\text{MB}_I \right)
	\Psi^\text{elec}_{\Iel}(\vec{X}, \vec{x}) \Psi^\text{nuc}_{\Inu}(\vec{X}) \\
	&\stackrel{\eqref{eqn:BONuclearDerivative}}{\simeq}
	\left( \Op{H}^\text{elec} \Psi^\text{elec}_{\Iel}(\vec{X}, \vec{x}) \Psi^\text{nuc}_{\Inu}(\vec{X}) \right)
	+ \Psi^\text{elec}_{\Iel}(\vec{X}, \vec{x}) \left(\Op{T}_n \Psi^\text{nuc}_{\Inu}(\vec{X}) \right)
	- E^\text{MB}_{I} \Psi^\text{MB}_I(\vec{X}, \vec{x})
	\\
	&\stackrel{\eqref{eqn:ElectronicSchrödinger}}{=}
	\Psi^\text{elec}_{\Iel}(\vec{X}, \vec{x})
	\left(E^\text{elec}_{\Iel}(\vec{X}) \Psi^\text{nuc}_{\Inu}(\vec{X})
	+ \Op{T}_n \Psi^\text{nuc}_{\Inu}(\vec{X})
	- E^\text{MB}_I \Psi^\text{nuc}_{\Inu}(\vec{X}) \right).
\end{align*}
This statement is satisfied provided that the nuclear wave function
$\Psi^\text{nuc}_{\Inu}(\vec{X})$
follows the \newterm{nuclear Schrödinger equation}
\begin{equation}
	\left( \Op{T}_n + E^\text{elec}_{\Iel}(\vec{X}) \right)
	\Psi^\text{nuc}_{\Inu}(\vec{X})
	= E^\text{MB}_I \Psi^\text{nuc}_{\Inu}(\vec{X}).
	\label{eqn:NuclearSchrödinger}
\end{equation}

Overall the Born-Oppenheimer approximation
allows to solve the many-body Schrödinger equation \eqref{eqn:TISEManyBody} in two steps.
First we limit ourselves to the point of view of the electrons
under the electric field induced by fixed, motionless nuclei.
This leads to \eqref{eqn:ElectronicSchrödinger},
which is solved for the
electronic states $\Psi^\text{elec}_{\Iel}(\vec{X}, \vec{x})$
along with corresponding electronic energies $E^\text{elec}_{\Iel}(\vec{X})$.
In the second step we consider nuclear motion by solving
\eqref{eqn:NuclearSchrödinger}.
In this equation the electronic energies $E^\text{elec}_{\Iel}(\vec{X})$
depending on the nuclear coordinates act as the electrostatic potential
in which the nuclei move.
For this reason $E^\text{elec}_{\Iel}(\vec{X})$ is sometimes
called a \newterm{potential energy surface} as well.
Note, that each electronic state characterised by quantum numbers $\Iel$
gives rise to a different potential energy surface.

Employing a more detailed treatment of the Born-Oppenheimer approximation,
like in the original paper \cite{Born1927} or \citet{Baer2006},
allows to gain more insight regarding the range of applicability
of the Born-Oppenheimer approximation.
Loosely speaking it is a valid approximation
as long as the potential energy surfaces $E^\text{elec}_{\Iel}(\vec{X})$
are well-separated from another.

From a numerical point of view this approximation allows to reduce
the dimensionality of the problem somewhat.
To illustrate this let us return to the water molecule,
which was already discussed at the end of section \vref{sec:ManyBodyTISE}.
In the exact problem we need to solve one equation,
namely the many-body Schrödinger equation \eqref{eqn:TISEManyBody}
of dimensionality $L = 39$.
Within the Born-Oppenheimer approximation
this is replaced by solving two equations,
the electronic one \eqref{eqn:ElectronicSchrödinger} of dimensionality $3 \Nelec = 30$
and the nuclear TISE \eqref{eqn:NuclearSchrödinger} of dimensionality $3 M = 9$.
In the estimate we presented in section \vref{sec:ManyBodyTISE}
for the $L^2$ inner products,
this would roughly provide a speed-up factor of $10^9$.

\subsection{Electronic Schrödinger equation}
\label{sec:ElectronicSchrödinger}
By solving the electronic Schrödinger equation \eqref{eqn:ElectronicSchrödinger}
we get access to the electronic states $\Psi^\text{elec}_{\Iel}(\vec{X}, \vec{x})$
as well as the potential energy surface $E^\text{elec}_{\Iel}(\vec{X})$.
In many cases these quantities already provide
enough insight into a chemical system in order to address many
questions relevant to quantum chemistry.
For this reason the nuclear Schrödinger equation \eqref{eqn:NuclearSchrödinger}
will be neglected in this work from now on
and we will focus only
on approximation methods for solving \eqref{eqn:ElectronicSchrödinger} instead.

For ease of notation we will usually drop the indices ``e'' and the
superscripts ``elec'' from now on if we refer to electronic energies
or the electronic part of the wave function.
Similarly in the context of the electronic Schrödinger equation
the nuclei are motionless, which makes $\vec{X}$ a fixed quantity.
Thus we drop the nuclear coordinates ``$\vec{X}$''
from the function arguments, too.
In this convention we would for example
write the electronic Schrödinger equation \eqref{eqn:ElectronicSchrödinger} as
\[ \Op{H} \Psi_I(\vec{x}) = E_I \Psi_I(\vec{x}). \]
Another simplification we sometimes employ is to consider
the simplified electronic Hamiltonian
\begin{equation}
	\Op{H}_{\Nelec} \equiv \Op{H}^\text{elec} - \Op{V}_{nn}
	= -\frac12 \sum_{i=1}^{\Nelec} \Delta_{\vec{r}_i}
	- \sum_{A=1}^M \sum_{i=1}^{\Nelec} \frac{Z_A}{r_{iA}}
	+ \sum_{i=1}^{\Nelec} \sum_{j=i+1}^{\Nelec} \frac{1}{r_{ij}}
	\label{eqn:ElectronicHamiltonian}
\end{equation}
instead of $\Op{H}^\text{elec}$.
This is possible, since the potential operator governing the Coulombic interaction
amongst the nuclei
\[
	\Op{V}_{nn} = \sum_{A=1}^M \sum_{B=A+1}^M \frac{Z_A Z_B}{r_{AB}}
\]
only depends on $\vec{X}$, which makes it a constant value for one particular chemical system.
In many cases one can therefore work with $\Op{H}_{\Nelec}$
in a numerical treatment and only add the nuclear potential energy term $\Op{V}_{nn}$
afterwards.

In analogy to the many-body Hamiltonian \eqref{eqn:ManyBodyHamiltonian}
and the hydrogen-like Hamiltonian \eqref{eqn:OpHydrogen}
we choose the underlying Hilbert space of $\Op{H}_{\Nelec}$
to be $L^2(\R^{3\Nelec}, \C)$.
Due to Kato's theorem~\cite{Kato1951} $\Op{H}_{\Nelec}$
becomes self-adjoint if we set its domain to $D(\Op{H}_{\Nelec}) = H^2(\R^{3\Nelec}, \C)$.
Not all functions in $H^2(\R^{3\Nelec}, \C)$ are physical, however~\cite{Mueller2000,Shankar1994}.
This is due to the fact that electrons do not only show spatial degrees of freedom,
but furthermore an intrinsic angular momentum degree of freedom
called \newterm{spin}.
More precisely electrons are so-called spin-$\sfrac12$ particles.
By the spin statistics theorem~\cite{Shankar1994} of quantum field theory
this requires the electronic wave function
to be antisymmetric with respect to particle exchange.
More symbolically all eigenfunctions $\Psi_I$ of $\Op{H}_{\Nelec}$
need to satisfy the condition
\begin{equation}
	\forall i,j \in \{1, 2, \ldots, \Nelec\}: \qquad
	  \Psi_I(\ldots, \vec{r}_i, \ldots, \vec{r}_j, \ldots) =
	- \Psi_I(\ldots, \vec{r}_j, \ldots, \vec{r}_i, \ldots).
	\label{eqn:AsymElecWavefunction}
\end{equation}
It is easy to see that not all elements of $H^2(\R^{3\Nelec}, \C)$ satisfy this.

Given that the classical correspondence
of \vref{sec:QMCorrespondence} did not yield any kind of spin degree of freedom
for non-relativistic \QM,
one might wonder at this point
why we need to bother with spin and the resulting
antisymmetry of the wave function at all in our physical model.
As it turns out many fundamental experimental results
and observations made at the beginning of the $20^\text{th}$ century
can only be explained if proper spin statistics is taken into account.
This includes the Stern-Gerlach experiment~\cite{Gerlach1922b,Gerlach1922,Gerlach1922a},
the spectral properties of atoms~\cite{Pauli1925}
and Fermi-Dirac statistics~\cite{Dirac1926},
just to name a few.
Even though spin can only be rigorously derived
using more sophisticated theories like
relativistic \QM or quantum field theory~\cite{Shankar1994},
one still needs to include it \textit{ad hoc} in non-relativistic \QM as well
such that above observations can be explained~\cite{Pauli1925,Shankar1994,Straumann2004}.

Notice, that a proper inclusion of spin in non-relativistic \QM
requires two modifications.
First we need each wave function to include an extra spin degree of freedom%
~\cite{Pauli1925}.
Secondly, we need to make sure that \eqref{eqn:AsymElecWavefunction}
is always satisfied~\cite{Dirac1926}.
We will defer the first modification to remark \vref{rem:Spin}
in order to yield a simpler mathematical treatment for now.
Unfortunately we cannot ignore \eqref{eqn:AsymElecWavefunction}
due to its tremendous impact on the mathematical structure of the emerging problems%
~\cite{Dirac1926,Fock1930}.

% TODO OPTIONAL
%\to doil{
%	I really would like to know more about the relationship
%	between Slater determinants and exterior products.
%	Go and ask someone about this.
%	The internet was not very helpful.
%}
There are a couple of approaches which could be followed
to adhere to \eqref{eqn:AsymElecWavefunction}.
Typically one abstains from modifying the Hamiltonian $\Op{H}_{\Nelec}$
and instead restricts the search space for the eigenstates $\Psi_I$
to an appropriate subspace of $L^2(\R^{3\Nelec}, \C)$,
which is constructed in a way
to enforce the required
antisymmetry with respect to the electronic coordinates~\cite{Dirac1926,Fock1930}.
Such a space is the $\Nelec$-th \newterm{exterior power} of $L^2(\R^3, \C)$ defined as
\newcommand{\wedgestring}{\psi_1 \wedge \psi_2 \wedge \cdots \wedge \psi_{\Nelec}}

\begin{equation}
	\bigwedge^{\Nelec} L^2(\R^3, \C)
	\equiv \spacespan \Big\{ \wedgestring
	\, \Big| \, \psi_i \in L^2(\R^3, \C) \, \forall i = 1, \ldots \Nelec \Big\}.
	\label{eqn:DefExteriorPower}
\end{equation}
The key component of this definition is the \newterm{wedge product}
or \newterm{exterior product} $f \wedge g$.
This product is totally antisymmetric with respect to its operands
and is closely related to the tensor product $f \otimes g$.
For example if $f, g \in L^2(\R^3, \C)$, then $f \wedge g \in L^2(\R^6, \C)$.
In some sense one can think of the wedge product
as a generalisation of the  cross product $\vec{a} \times \vec{b}$
for vectors $\vec{a}, \vec{b} \in \R^3$.
This is somewhat apparent from its properties.
Notice for example
\begin{align}
	\label{eqn:PropertiesExteriorProduct}
	\psi_1 \wedge \psi_1 &= 0, &\psi_1 \wedge \psi_2 &= -\psi_2 \wedge \psi_1, &
	\psi_1 \wedge (c_1 \psi_1 + c_2 \psi_2) &= c_2 \psi_1 \wedge \psi_2
\end{align}
for any $\psi_1, \psi_2 \in L^2(\R^3, \C)$ and any $c_1, c_2 \in \C$.
One may identify the application of a wedge product string like
\[ \bigwedge_{i=1}^{\Nelec} \psi_i \equiv \wedgestring \]
onto the electronic coordinates $\vec{x}$
with the evaluation of a determinant, \ie
\begin{align*}
	\left( \bigwedge_{i=1}^{\Nelec} \psi_i \right) (\vec{x})
	&\equiv \Big(\wedgestring\Big) (\vec{r}_1, \vec{r}_2, \ldots, \vec{r}_{\Nelec}) \\
	\equiv \frac{1}{\sqrt{\Nelec}} &\det
	\left(
	\begin{array}{*{6}{l}}
		\psi_1(\vec{r}_1) & \psi_2(\vec{r}_1) & \cdots & \psi_{\Nelec}(\vec{r}_1) \\
		\psi_1(\vec{r}_2) & \psi_2(\vec{r}_2) & \cdots & \psi_{\Nelec}(\vec{r}_2) \\
		\vdots & \vdots & \ddots & \vdots \\
		\psi_1(\vec{r}_{\Nelec}) & \psi_2(\vec{r}_{\Nelec}) & \cdots & \psi_{\Nelec}(\vec{r}_{\Nelec}) \\
	\end{array}
	\right).
\end{align*}
Because of this observation $\wedgestring$
is typically called a \newterm{Slater determinant}%
\footnote{After John~Slater, who introduced it.~\cite{Slater1929,Slater1930a}.}
in standard quantum-chemistry textbooks~\cite{Szabo1996,Helgaker2013}.
The functions $\psi_i \in L^2(\R^3, \C)$
are usually called \newterm{single-particle functions},
since they only depend on a single electronic coordinate.
Another way of phrasing \eqref{eqn:DefExteriorPower}
is therefore that $\bigwedge^{\Nelec} L^2(\R^3, \C)$
is the space spanned by all Slater determinants
consisting of $\Nelec$ single-particle functions from $L^2(\R^3, \C)$.
Notice, that%
\footnote{%
	This observation is the reason why the single-particle functions
	need to be square-integrable, \ie from $L^2(\R^3, \C)$.
}
\[ \bigwedge^{\Nelec} L^2(\R^3, \C) \subset L^2(\R^{3\Nelec}, \C), \]
exterior power on the left hand side is even dense in the space on the right.

If we want to encode condition \eqref{eqn:AsymElecWavefunction}
into our problem an easy solution is to combine this with Kato's theorem
and employ the domain
\begin{equation}
	D(\Op{H}_{\Nelec}) = H^2(\R^{3\Nelec}, \C) \cap \bigwedge^{\Nelec} L^2(\R^3, \C)
	\label{eqn:ElectronicHamiltonianDomain}
\end{equation}
for the electronic Hamiltonian $\Op{H}_{\Nelec}$.
This makes both the operator self-adjoint and the electronic wave function
comply with the spin statistics theorem.
Applying similar arguments to section \vref{sec:FormDomain},
we can deduce the analogous form domain of $\Op{H}_{\Nelec}$ as
\[ Q(\Op{H}_{\Nelec}) = H^1(\R^{3\Nelec}, \C) \cap \bigwedge^{\Nelec} L^2(\R^3, \C). \]
For establishing the spectral properties of $\Op{H}_{\Nelec}$,
there is first the important HVZ theorem~\cite{Zhislin1959,Zhislin1960,Reed1978,Teschl2014}
after Hunziker, van Winter and Zhislin.
\begin{thm}[HVZ]
	\label{thm:HVZ}
	Let $\Op{H}_{\Nelec}$ be the self-adjoint operator of \eqref{eqn:ElectronicHamiltonian}
	on the Hilbert space $L^2(\R^{3\Nelec}, \C)$
	with the domain given in \eqref{eqn:ElectronicHamiltonianDomain}.
	Then $\Op{H}_{\Nelec}$ is bounded from below and
	its essential spectrum%
	\footnote{For a definition see \vref{defn:EssentialSpectrum}.} is
	\[ \sigma_\text{ess}\left(\Op{H}_{\Nelec}\right) = [\Sigma_{\Nelec}, +\infty) \]
	with
	\[ \Sigma_{\Nelec} = \left\{
		\begin{array}{ll}
			0 & \text{ if $\Nelec = 1$} \\
			\inf \sigma\left(\Op{H}_{\Nelec-1}\right) < 0 & \text{ if $\Nelec \geq 2$}
		\end{array}
		\right. .
	\]
\end{thm}
This theorem establishes a link between
the lower bound of the essential spectrum $\sigma_\text{ess}$
of the electronic Hamiltonian of a $\Nelec$-electron system
and the lower bound of the complete spectrum $\sigma$ of
a corresponding $\Nelec - 1$ electron system
with the same nuclear arrangement.

For characterising the discrete spectrum of $\Op{H}_{\Nelec}$
we employ the important results by \citet{Zhislin1961} and \citet{Yafaev1976},
summarised by the following proposition.
\begin{prop}
	\label{prop:ZhislinYafaev}
	Let $\Op{H}_{\Nelec}$ be the $\Nelec$-electron electronic Hamiltonian
	operator of \eqref{eqn:ElectronicHamiltonian}
	with domain as stated in \eqref{eqn:ElectronicHamiltonianDomain}.
	Let further $Z_\text{tot} \equiv \sum_{A=1}^M Z_A$ denote the total nuclear charge.
	\begin{itemize}
		\item If $\Nelec \leq Z_\text{tot}$, \ie we consider a \emph{neutral}
			or \emph{positively charged} system, then
			$\Op{H}_{\Nelec}$
			has an infinite number of discrete eigenvalues
			below the essential spectrum.
		\item If $\Nelec \geq 1 + Z_\text{tot}$ (\emph{negatively charged} system),
			then $\Op{H}_{\Nelec}$ has \emph{at most} a finite number of discrete
			states below the essential spectrum.
	\end{itemize}
	\begin{proof}
		See~\cite{Zhislin1961,Yafaev1976}.
	\end{proof}
\end{prop}
Before we discuss the physical interpretation of these results,
let us first introduce some terminology.
If we are either concerned with a neutral or positively charged
$\Nelec$-electron system or a negatively charged system
with at least a single discrete eigenvalue, we can define a \newterm{ground-state energy}
\begin{equation}
	E^{\Nelec}_0 = \min \sigma\left(\Op{H}_{\Nelec}\right) = \Sigma_{\Nelec+1}.
	\label{eqn:GroundStateEnergy}
\end{equation}
The energies of the discrete spectrum are ordered as usual
\[ E^{\Nelec}_0 \leq E^{\Nelec}_1 \leq E^{\Nelec}_2 \leq \cdots \]
and associated with these eigenvalues are the corresponding (bound) eigenstates
\[ \Psi_0, \Psi_1, \Psi_2, \ldots. \]
All states $\Psi_i$ which have an energy eigenvalue $E^{\Nelec}_i = E^{\Nelec}_0$
are commonly referred to as the \newterm{ground state}.
If $E^{\Nelec}_0$ is not degenerate by construction
$\Psi_0$ is the ground state.
All other states $\Psi_i$ with $E^{\Nelec}_i \neq E^{\Nelec}_0$
are called \newterm{excited states}.

For negatively charged systems we similarly use the
term ``ground state'' to refer to the state or states corresponding
to the lowest eigenvalue of $\sigma_P\left(\Op{H}_{\Nelec}\right)$
and ``excited states'' for the other eigenfunctions of $\Op{H}_{\Nelec}$.
Note, however, that for negatively charged systems
the case \mbox{$\inf \sigma\left(\Op{H}_{\Nelec}\right) \leq E^{\Nelec}_0$} is possible%
~(see proposition \ref{prop:ZhislinYafaev}),
\ie that the lowest-energy bound state is already embedded inside the continuum.

\begin{rem}[Physical interpretation of the spectrum]
	In this remark we will summarise the results,
	which can be deduced from the HVZ theorem \ref{thm:HVZ}
	and from proposition \vref{prop:ZhislinYafaev}.

	% TODO OPTIONAL
	%\to doil{Figure ?}
	Let us first consider a neutral or positively charged
	system with $\Nelec$ electrons.
	It has a ground states as well as an infinite number
	of discrete and bound excited states
	until the ground-state energy $E^{\Nelec-1}_0$
	of the corresponding $(\Nelec-1)$-electron
	with the same nuclear arrangement is hit.
	Note, that we can be sure that $E^{\Nelec-1}_0$
	exists, because the $(\Nelec-1)$-electron system
	is positively charged.
	This behaviour is easy to understand physically.
	As soon as the energy $E^{\Nelec-1}_0$ is reached
	our $\Nelec$-electron system can always
	separate into a stable system with $\Nelec-1$
	bound electrons and an unbound $\Nelec$-th electron
	taking the excess energy into the continuum.
	From this we can easily understand the energy difference
	$E^{\Nelec-1}_0 - E^{\Nelec}_0$
	as the ionisation energy.
	Note, that embedded inside the emerging continuum
	at energies beyond $E^{\Nelec-1}_0$
	may still be bound states of the $(\Nelec-1)$-electron system
	or the $\Nelec$-system.
	In other words in general we have
	\[ \sigma_C\left(\Op{H}_{\Nelec}\right)
		\subsetneq \sigma_\text{ess}\left(\Op{H}_{\Nelec}\right). \]

	If the $\Nelec$-system is of single negative charge
	and possesses no bound states below the essential spectrum,
	this implies
	\[ \inf \sigma\left(\Op{H}_{\Nelec}\right)
		= \inf \sigma\left(\Op{H}_{\Nelec-1}\right) = E^{\Nelec-1}_0, \]
	since the $\Nelec-1$-electron system is neutral,
	thus possesses a ground state.
	In other words all bound states of this system
	are embedded inside the continuum.
	The system thus may separate into a bound $(\Nelec-1)$-electron system
	and an unbound electron at all energies:
	This negative ion is not stable.
	Conversely for stable negative ions
	we would expect at least a single bound state to exist.

	Unlike neutral or positively charged systems,
	negatively charged systems in each case only possess a
	finite number of bound states below
	the essential spectrum.

	To summarise this remark, let us note the following
	interesting observations,
	which are now backed by rigorous mathematical treatment:
	\begin{itemize}
		\item The essential spectrum marks the energies
			at which a chemical system is unstable,
			because it can separate into (one or more) unbound electron
			plus a stable system with a
			reduced number of bound electrons.
		\item Forming a positive ion always costs energy.
		\item All systems with more than one electron
			will produce unbound electrons,
			\ie ionise, at large-enough energies (in vacuum).
		\item Not all negative ions possess a stable ground state (in vacuum).
		\item All positive ions possess a stable ground state (in vacuum).
	\end{itemize}
\end{rem}

\begin{rem}[Consequences for a numerical treatment]
	\label{rem:ElectronicTISENumerical}
	From proposition \ref{prop:ZhislinYafaev}
	we can immediately deduce,
	that there are no problems with neutral or positively charged
	systems under a variational numerical treatment as discussed
	in section \vref{sec:Projection}.
	Both the ground state as well as the first few
	excited states are located below the
	essential spectrum and thus accessible for the treatment
	described in remark \vref{rem:ApproxBottomDiscrete}.

	For negative ions we might get into trouble.
	If the ion is stable,
	then at least its ground state can be approximated
	numerically via remark \ref{rem:ApproxBottomDiscrete}.
	If it is not, we might not even be able to get its ground state.
	The problem is, that in a variational numerical treatment
	we cannot easily distinguish between approximations
	to bound states and approximations to continuum states
	if they are located in the same energy range.
	So if the lowest-energy bound state is embedded inside the continuum,
	both are inside the essential spectrum.
	A variational treatment will converge to the bottom end
	of the essential spectrum~(see theorem \ref{thm:CourantFischer}),
	which might not be the lowest-energy bound state in this case.
\end{rem}
